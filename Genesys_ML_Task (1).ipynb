{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the aim here is to create a machine learning algorithm that the company can use to determine the clients that it should target in order to enroll them as new customers. We are therefore trying to classify whether a customer is likely to buy car insurance from the company or not and hence this is a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "        ... \n",
      "3995    3996\n",
      "3996    3997\n",
      "3997    3998\n",
      "3998    3999\n",
      "3999    4000\n",
      "Name: Id, Length: 4000, dtype: int64\n",
      "['Id', 'Age', 'Job', 'Marital', 'Education', 'Default', 'Balance', 'HHInsurance', 'CarLoan', 'Communication', 'LastContactDay', 'LastContactMonth', 'NoOfContacts', 'DaysPassed', 'PrevAttempts', 'Outcome', 'CallStart', 'CallEnd', 'CarInsurance']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('C:/Users/lhaye/Documents/Genesys_Task_Dataset/carInsurance_train.csv')\n",
    "test_df = pd.read_csv('C:/Users/lhaye/Documents/Genesys_Task_Dataset/carInsurance_test.csv')\n",
    "\n",
    "print(train_df['Id'])\n",
    "\n",
    "#LETS PUT THE COLUMNS INTO A LIST SO WE CAN SEE WHICH ONES CORRESPOND TO FEATURES AND WHICH TO \n",
    "columns = train_df.columns.tolist()\n",
    "feature_columns = columns[:-1]\n",
    "output_column = columns[-1:]\n",
    "num_train_samples = train_df.shape[0]\n",
    "\n",
    "print(columns)\n",
    "\n",
    "#Okay so lets do some analysis of the data \n",
    "#print(train_df.shape)\n",
    "\n",
    "#We can see from this that we have many categorical features which we will have to transform into numeric features\n",
    "#print(train_df.info)\n",
    "\n",
    "#Lets also check the types and we can see that the object type represents a categorical feature which we will have to change\n",
    "#print(train_df.dtypes)\n",
    "\n",
    "#Any preprocessing we do should be done in a function because we will have to do the same for the test set \n",
    "#We need to check for and deal with the following if they are present:\n",
    "#1 Missing data (na or nan)\n",
    "#2 Duplicate data - samples that are present twice - we can just remove one if they are identical \n",
    "#3 Modify categorical features\n",
    "#4 Outliers - values that are very high for example we can see that there has been 12 previous attempts to contact one customer\n",
    "#5 Create some new features from the data\n",
    "#6 Remove irrelevant features/columns \n",
    " \n",
    "\n",
    "#Lets get the preprocessed data and then make alterations to it based on the model score \n",
    "def preprocess_data(data):\n",
    "    \n",
    "    #1 Missing data \n",
    "    #print(data.isnull().sum())\n",
    "    #We can see that the columns with missing data is present where we have categorical data so when we change these \n",
    "    #to numeric data we can simply add in a value to represent NA - This should sort this issue \n",
    "    \n",
    "    #2 Duplicate data\n",
    "    duplicate_rows_df = data[data.duplicated()]\n",
    "    #print('number of duplicate rows: ', duplicate_rows_df.shape)\n",
    "    #We can see we have zero duplicated rows of data \n",
    "    \n",
    "    \n",
    "    #3 Modify all data that is Na with a word to avoid difficulties \n",
    "    data['Education'] = data['Education'].fillna(\"NoVal\")\n",
    "    data['Job'] = data['Job'].fillna(\"NoVal\")\n",
    "    data['Communication'] = data['Communication'].fillna(\"NoVal\")\n",
    "    data['Outcome'] = data['Outcome'].fillna(\"NoVal\")\n",
    "\n",
    "    #We tranlsate the categorical labels into numeric labels \n",
    "    ord_enc = OrdinalEncoder()\n",
    "    #print(data)\n",
    "    data[\"Education\"] = ord_enc.fit_transform(data[[\"Education\"]])\n",
    "    data[\"Marital\"] = ord_enc.fit_transform(data[[\"Marital\"]])\n",
    "    data[\"Job\"] = ord_enc.fit_transform(data[[\"Job\"]])\n",
    "    data[\"Outcome\"] = ord_enc.fit_transform(data[[\"Outcome\"]])\n",
    "    data[\"Communication\"] = ord_enc.fit_transform(data[[\"Communication\"]])\n",
    "\n",
    "    #Create a feature for the duration of the call \n",
    "    data['CallStart'] = pd.to_datetime(data[\"CallStart\"])\n",
    "    data['CallEnd'] = pd.to_datetime(data[\"CallEnd\"])\n",
    "\n",
    "    data['CallStart'] = (data['CallStart'].dt.hour*60+data['CallStart'].dt.minute)*60 + data['CallStart'].dt.second\n",
    "    data['CallEnd'] = (data['CallEnd'].dt.hour*60+data['CallEnd'].dt.minute)*60 + data['CallEnd'].dt.second\n",
    "    \n",
    "    data['CallDuration'] = data['CallEnd'] - data['CallStart']\n",
    "    #Now we have the feature and some of the values are quite large so perhaps they should be normalised \n",
    "    \n",
    "    #Now we should drop some features that we dont need \n",
    "    data = data.drop(['Id', 'LastContactDay', 'LastContactMonth', 'CallStart', 'CallEnd'], axis=1)\n",
    "    \n",
    "    #Now we need to normalise/put into smaller values the following columns\n",
    "    # Balance\n",
    "    # DaysPassed\n",
    "    # NoOfContacts\n",
    "    \n",
    "    #NORMALIZATION WE CAN TAKE THIS OUT DEPENDENT ON WHAT ALGORITHM WE USE \n",
    "    # Maybe because the max is so infrequent we should do a different form of normalization but we can see later\n",
    "    data['Balance'] = (data['Balance'] - data['Balance'].min()) / (data['Balance'].max() - data['Balance'].min())\n",
    "    data['NoOfContacts'] = (data['NoOfContacts'] - data['NoOfContacts'].min()) / (data['NoOfContacts'].max() - data['NoOfContacts'].min())\n",
    "    data['Age'] = (data['Age'] - data['Age'].min()) / (data['Age'].max() - data['Age'].min())\n",
    "    data['DaysPassed'] = (data['DaysPassed'] - data['DaysPassed'].min()) / (data['DaysPassed'].max() - data['DaysPassed'].min())\n",
    "    data['PrevAttempts'] = (data['PrevAttempts'] - data['PrevAttempts'].min()) / (data['PrevAttempts'].max() - data['PrevAttempts'].min())\n",
    "    data['CallDuration'] = (data['CallDuration'] - data['CallDuration'].min()) / (data['CallDuration'].max() - data['CallDuration'].min())\n",
    "    data['Job'] = (data['Job'] - data['Job'].min()) / (data['Job'].max() - data['Job'].min())\n",
    "    data['Education'] = (data['Education'] - data['Education'].min()) / (data['Education'].max() - data['Education'].min())\n",
    "    data['Marital'] = (data['Marital'] - data['Marital'].min()) / (data['Marital'].max() - data['Marital'].min())\n",
    "    data['Communication'] = (data['Communication'] - data['Communication'].min()) / (data['Communication'].max() - data['Communication'].min())\n",
    "\n",
    "    print(len(data))\n",
    "    \n",
    "    return data\n",
    "    #Okay so now we have the features we need so we can return them and see how it would go on a dataset\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "1\n",
      "      CarInsurance\n",
      "3215             0\n",
      "3126             0\n",
      "697              0\n",
      "3613             0\n",
      "2374             1\n",
      "...            ...\n",
      "1130             0\n",
      "1294             0\n",
      "860              1\n",
      "3507             1\n",
      "3174             0\n",
      "\n",
      "[2800 rows x 1 columns]\n",
      "           Age       Job  Marital  Education  Default   Balance  HHInsurance  \\\n",
      "0     0.181818  0.454545      1.0   1.000000        0  0.042138            1   \n",
      "1     0.181818  0.181818      0.5   0.333333        0  0.041527            1   \n",
      "2     0.142857  0.454545      1.0   1.000000        0  0.036413            1   \n",
      "3     0.090909  0.818182      1.0   0.333333        0  0.033811            1   \n",
      "4     0.155844  0.454545      0.5   1.000000        0  0.056684            0   \n",
      "...        ...       ...      ...        ...      ...       ...          ...   \n",
      "3995  0.129870  0.909091      1.0   1.000000        0  0.030136            1   \n",
      "3996  0.402597  0.090909      0.0   0.666667        0  0.031357            1   \n",
      "3997  0.116883  0.090909      1.0   0.666667        0  0.026194            0   \n",
      "3998  0.233766  0.272727      1.0   1.000000        0  0.036620            1   \n",
      "3999  0.350649  0.727273      0.5   0.333333        0  0.031486            1   \n",
      "\n",
      "      CarLoan  Communication  NoOfContacts  DaysPassed  PrevAttempts  Outcome  \\\n",
      "0           0            1.0      0.023810    0.000000      0.000000      0.0   \n",
      "1           0            0.0      0.095238    0.000000      0.000000      0.0   \n",
      "2           0            0.5      0.000000    0.140351      0.017241      1.0   \n",
      "3           0            0.5      0.023810    0.000000      0.000000      0.0   \n",
      "4           0            0.5      0.000000    0.000000      0.000000      0.0   \n",
      "...       ...            ...           ...         ...           ...      ...   \n",
      "3995        0            0.5      0.000000    0.047953      0.034483      1.0   \n",
      "3996        1            0.5      0.428571    0.000000      0.000000      0.0   \n",
      "3997        1            0.5      0.000000    0.000000      0.000000      0.0   \n",
      "3998        0            0.5      0.000000    0.266667      0.051724      1.0   \n",
      "3999        0            0.0      0.023810    0.000000      0.000000      0.0   \n",
      "\n",
      "      CallDuration  \n",
      "0         0.020012  \n",
      "1         0.055419  \n",
      "2         0.103140  \n",
      "3         0.250616  \n",
      "4         0.057574  \n",
      "...            ...  \n",
      "3995      0.081281  \n",
      "3996      0.036946  \n",
      "3997      0.087746  \n",
      "3998      0.028941  \n",
      "3999      0.082820  \n",
      "\n",
      "[4000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train_processed = preprocess_data(train_df)\n",
    "print(len(output_column))\n",
    "y_train_vals = train_df[output_column]\n",
    "x_train_processed = x_train_processed.drop(labels='CarInsurance', axis=1)\n",
    "print(y_train)\n",
    "\n",
    "\n",
    "print(x_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with the train and test \n",
    "#train_df = pd.concat([x_train, y_train], axis=1)\n",
    "\n",
    "#print(x_train_processed)\n",
    "#print(len(y_train))\n",
    "\n",
    "#Now we should create a train and validation split of the data and do some predictions\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train_processed, y_train_vals, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(X_train)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Logistic Regression achieves a mean accuracy result of 79.40625 over a 10-fold validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Support Vector Machine Linear achieves a mean accuracy result of 79.8125 over a 10-fold validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Support Vector Machine Rbf achieves a mean accuracy result of 79.18749999999999 over a 10-fold validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Support Vector Machine NuSVC achieves a mean accuracy result of 80.3125 over a 10-fold validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest achieves a mean accuracy result of 81.71875 over a 10-fold validation set\n",
      "The Decision Tree achieves a mean accuracy result of 73.625 over a 10-fold validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The K-Nearest Neighbours achieves a mean accuracy result of 74.65625000000001 over a 10-fold validation set\n",
      "The Linear Discriminant Analysis achieves a mean accuracy result of 78.90625 over a 10-fold validation set\n",
      "The Naive Bayes achieves a mean accuracy result of 65.28124999999999 over a 10-fold validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Boosting achieves a mean accuracy result of 82.09375 over a 10-fold validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The An Ensemble achieves a mean accuracy result of 79.875 over a 10-fold validation set\n",
      "The models with the top 3 results are: \n",
      "Boosting\n",
      "Random Forest\n",
      "Support Vector Machine NuSVC\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Now lets run using k-fold cross validation to get the best \n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scoring = ['accuracy']\n",
    "\n",
    "models = [\n",
    "          ('Logistic Regression', LogisticRegression()), \n",
    "          ('Support Vector Machine Linear', svm.SVC(kernel='linear')),\n",
    "          ('Support Vector Machine Rbf', svm.SVC(kernel='rbf')),\n",
    "          ('Support Vector Machine NuSVC', svm.NuSVC(gamma='auto')), \n",
    "          ('Random Forest', RandomForestClassifier(n_estimators = 100, random_state=1)),\n",
    "          ('Decision Tree', DecisionTreeClassifier(max_depth=1)),\n",
    "          ('K-Nearest Neighbours', KNeighborsClassifier(n_neighbors=5)), \n",
    "          ('Linear Discriminant Analysis', LinearDiscriminantAnalysis()),\n",
    "          ('Naive Bayes', MultinomialNB()),\n",
    "          ('Boosting', GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=1, random_state=1)), \n",
    "          ('An Ensemble', VotingClassifier(estimators=[('boost', boosting), ('SVM', SVMmodelNuSVC) , ('rf', RFModel)], voting = 'hard'))\n",
    "        ]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models:\n",
    "\n",
    "    kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    avg_accuracy = np.mean(cv_results['test_accuracy']) * 100 \n",
    "    print(f\"The {name} achieves a mean accuracy result of {avg_accuracy} over a 10-fold validation set\")\n",
    "    results[name] = avg_accuracy\n",
    "    \n",
    "    \n",
    "top_3_models = sorted(results, key=results.get, reverse=True)[:3]\n",
    "\n",
    "for i in range(len(top_3_models)):\n",
    "    if(i == 0):\n",
    "        print(\"The models with the top 3 results are: \")\n",
    "        print(top_3_models[i])\n",
    "    else:\n",
    "        print(top_3_models[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets take the top 3 and get the best parameters using grid search and then do some analysis of the scores of them\n",
    "#('Boosting', GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=1, random_state=1)), \n",
    "#('Random Forest', RandomForestClassifier(n_estimators = 100, random_state=1)),\n",
    "#('Support Vector Machine NuSVC', svm.NuSVC(gamma='auto')), \n",
    "\n",
    "#RFModel = RandomForestClassifier(random_state=1)\n",
    "\n",
    "#param_grid  = { \n",
    "    #'n_estimators': [40, 60, 80, 100, 200],\n",
    "    #'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    #'max_depth' : [1,2,3,4,5,6,7,8],\n",
    "    #'criterion' :['gini', 'entropy']\n",
    "#}\n",
    "\n",
    "#CV_rfc = GridSearchCV(estimator=RFModel, param_grid=param_grid, cv= 5)\n",
    "#CV_rfc.fit(X_train, y_train)\n",
    "#print(CV_rfc.best_params_)\n",
    "\n",
    "\n",
    "#Tomorrow \n",
    "#Wrap up model analysis and select the best \n",
    "#Then move on to the next part and get that finished tomorrow leaving \n",
    "#analysis of features and then some tidying up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.40624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:531: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.9375\n"
     ]
    }
   ],
   "source": [
    "#{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 60}\n",
    "RFModel = RandomForestClassifier(criterion= 'entropy', max_depth= 8, max_features= 'auto', n_estimators= 60, random_state=1)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "cv_results = model_selection.cross_validate(RFModel, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "avg_accuracy = np.mean(cv_results['test_accuracy']) * 100 \n",
    "print(avg_accuracy)\n",
    "\n",
    "\n",
    "RFModel = RandomForestClassifier(n_estimators= 100, random_state=1)\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "cv_results = model_selection.cross_validate(RFModel, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "avg_accuracy = np.mean(cv_results['test_accuracy']) * 100 \n",
    "print(avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:               0.78125\n",
      "SVM Linear Accuracy:                        0.795\n",
      "SVM SVC Accuracy:                           0.8075\n",
      "SVM NuSVC Accuracy:                         0.79625\n",
      "Random Forrest Accuracy:                    0.82375\n",
      "Decision Tree Accuracy:                     0.74875\n",
      "K-Nearest Neighbours Accuracy:              0.73\n",
      "Naive Bayes Accuracy:                       0.655\n",
      "Linear Discriminant Analysis Accuracy:      0.77875\n",
      "Boosting Accuracy:                          0.82125\n",
      "Adaboost Accuracy:                          0.81125\n",
      "Ensemble Accuracy:                          0.81875\n",
      "\n",
      "Logistic Regression Precision:             0.7786561264822134\n",
      "SVM Precision Linear:                      0.796875\n",
      "SVM Precision SVC:                         0.8068181818181818\n",
      "SVM Precision NuSVC:                       0.7976653696498055\n",
      "Random Forest Precision:                   0.7760252365930599\n",
      "Decision Tree Precision:                   0.7137546468401487\n",
      "Naive Bayes Precision:                     0.6086956521739131\n",
      "K-Nearest Neighbours Precision:            0.6798561151079137\n",
      "Linear Discriminant Analysis Accuracy:     0.7957446808510639\n",
      "Boosting Precision:                        0.7912457912457912\n",
      "Adaboost Precision:                        0.7835051546391752\n",
      "Ensemble Precision:                        0.7859531772575251\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "        \n",
    "#Now we can run an algorithm and see \n",
    "#start with Logistic regression\n",
    "\n",
    "#Logistic Regression Model\n",
    "#LRmodel = LRmodel.fit(X_train, y_train)\n",
    "LRscores = cross_val_score(LRmodel, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "#Support Vector Model with Linear Kernel \n",
    "SVMmodelLinear.fit(X_train, y_train)\n",
    "LRscores = cross_val_score(SVMmodelLinear, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "#Support Vector Model with RBF Kernel \n",
    "SVMmodelRbf.fit(X_train, y_train)\n",
    "\n",
    "#Support Vector Model with SVC Kernel \n",
    "SVMmodelNuSVC.fit(X_train, y_train)\n",
    "\n",
    "#Random Forest Model\n",
    "RFModel.fit(X_train, y_train)\n",
    "\n",
    "#Decision Tree Model \n",
    "DTModel.fit(X_train, y_train)\n",
    "\n",
    "#K-nearest neighbours model\n",
    "KNNModel.fit(X_train, y_train)\n",
    "\n",
    "#Linear Discriminant Analysis\n",
    "LDAModel.fit(X_train, y_train)\n",
    "\n",
    "#Niave Bayes Model\n",
    "NaiveBayesModel.fit(X_train, y_train)\n",
    "\n",
    "#Implement a boosting algorithm\n",
    "boosting.fit(X_train, y_train)\n",
    "\n",
    "#Adaboost\n",
    "Adaboost.fit(X_train, y_train)\n",
    "\n",
    "#Ensemble with 'hard' vote i.e. majority rules\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "#Implement a stacking algorithm \n",
    "\n",
    "#Lets use the logistic regression algorithm and get a result\n",
    "LRpredictions = LRmodel.predict(X_test)\n",
    "LRscore = accuracy_score(y_test, LRpredictions)\n",
    "LRPrecision = metrics.precision_score(y_test, LRpredictions)\n",
    "\n",
    "#Now lets use SVM and do the same \n",
    "SVMpredictionsLinear = SVMmodelLinear.predict(X_test)\n",
    "SVMscoreLinear = accuracy_score(y_test, SVMpredictionsLinear)\n",
    "SVMPrecisionLinear = metrics.precision_score(y_test, SVMpredictionsLinear)\n",
    "\n",
    "SVMpredictionsRbf = SVMmodelRbf.predict(X_test)\n",
    "SVMscoreRbf = accuracy_score(y_test, SVMpredictionsRbf)\n",
    "SVMPrecisionRbf = metrics.precision_score(y_test, SVMpredictionsRbf)\n",
    "\n",
    "SVMpredictionsNuSVC = SVMmodelNuSVC.predict(X_test)\n",
    "SVMscoreNuSVC = accuracy_score(y_test, SVMpredictionsNuSVC)\n",
    "SVMPrecisionNuSVC = metrics.precision_score(y_test, SVMpredictionsNuSVC)\n",
    "\n",
    "RFpredictions = RFModel.predict(X_test)\n",
    "RFscore = accuracy_score(y_test, RFpredictions)\n",
    "RFPrecision = metrics.precision_score(y_test, RFpredictions)\n",
    "\n",
    "DTpredictions = DTModel.predict(X_test)\n",
    "DTscore = accuracy_score(y_test, DTpredictions)\n",
    "DTPrecision = metrics.precision_score(y_test, DTpredictions)\n",
    "\n",
    "KNNpredictions = KNNModel.predict(X_test)\n",
    "KNNscore = accuracy_score(y_test, KNNpredictions)\n",
    "KNNPrecision = metrics.precision_score(y_test, KNNpredictions)\n",
    "\n",
    "LDApredictions = LDAModel.predict(X_test)\n",
    "LDAscore = accuracy_score(y_test, LDApredictions)\n",
    "LDAPrecision = metrics.precision_score(y_test, LDApredictions)\n",
    "\n",
    "NBpredictions = NaiveBayesModel.predict(X_test)\n",
    "NBscore = accuracy_score(y_test, NBpredictions)\n",
    "NBPrecision = metrics.precision_score(y_test, NBpredictions)\n",
    "\n",
    "Boostingpredictions = boosting.predict(X_test)\n",
    "Boostingscore = accuracy_score(y_test, Boostingpredictions)\n",
    "BoostingPrecision = metrics.precision_score(y_test, Boostingpredictions)\n",
    "\n",
    "Adaboostpredictions = Adaboost.predict(X_test)\n",
    "Adaboostscore = accuracy_score(y_test, Adaboostpredictions)\n",
    "AdaboostPrecision = metrics.precision_score(y_test, Adaboostpredictions)\n",
    "\n",
    "Ensemblepredictions = ensemble.predict(X_test)\n",
    "Ensemblescore = accuracy_score(y_test, Ensemblepredictions)\n",
    "EnsemblePrecision = metrics.precision_score(y_test, Ensemblepredictions)\n",
    "\n",
    "\n",
    "#Tasks this evening \n",
    "#2) Grid Search for each with their important hyperparameters \n",
    "#4) Add proper means of algorithmic analysis such as \n",
    "# Area Under the Curve \n",
    "# Confusion Matrix\n",
    "# F1 Score, Precision and Recall \n",
    "\n",
    "\n",
    "print(\"Logistic Regression Accuracy:              \", LRscore)\n",
    "print(\"SVM Linear Accuracy:                       \", SVMscoreLinear)\n",
    "print(\"SVM SVC Accuracy:                          \", SVMscoreRbf)\n",
    "print(\"SVM NuSVC Accuracy:                        \", SVMscoreNuSVC)\n",
    "print(\"Random Forrest Accuracy:                   \", RFscore)\n",
    "print(\"Decision Tree Accuracy:                    \", DTscore)\n",
    "print(\"K-Nearest Neighbours Accuracy:             \", KNNscore)\n",
    "print(\"Naive Bayes Accuracy:                      \", NBscore)\n",
    "print(\"Linear Discriminant Analysis Accuracy:     \", LDAscore)\n",
    "print(\"Boosting Accuracy:                         \", Boostingscore)\n",
    "print(\"Adaboost Accuracy:                         \", Adaboostscore)\n",
    "print(\"Ensemble Accuracy:                         \", Ensemblescore)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Logistic Regression Precision:            \", LRPrecision)\n",
    "print(\"SVM Precision Linear:                     \", SVMPrecisionLinear)\n",
    "print(\"SVM Precision SVC:                        \", SVMPrecisionRbf)\n",
    "print(\"SVM Precision NuSVC:                      \", SVMPrecisionNuSVC)\n",
    "print(\"Random Forest Precision:                  \", RFPrecision)\n",
    "print(\"Decision Tree Precision:                  \", DTPrecision)\n",
    "print(\"Naive Bayes Precision:                    \", NBPrecision)\n",
    "print(\"K-Nearest Neighbours Precision:           \", KNNPrecision)\n",
    "print(\"Linear Discriminant Analysis Accuracy:    \", LDAPrecision)\n",
    "print(\"Boosting Precision:                       \", BoostingPrecision)\n",
    "print(\"Adaboost Precision:                       \", AdaboostPrecision)\n",
    "print(\"Ensemble Precision:                       \", EnsemblePrecision)\n",
    "\n",
    "\n",
    "#Take the best 1/2/3 algorithms and run to see check the ROC curves, f1 scores, precision and recall \n",
    "#I will choose the best algorithm then \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
