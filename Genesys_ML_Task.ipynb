{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the aim here is to create a machine learning algorithm that the company can use to determine the clients that it should target in order to enroll them as new customers. We are therefore trying to classify whether a customer is likely to buy car insurance from the company or not and hence this is a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "        ... \n",
      "3995    3996\n",
      "3996    3997\n",
      "3997    3998\n",
      "3998    3999\n",
      "3999    4000\n",
      "Name: Id, Length: 4000, dtype: int64\n",
      "['Id', 'Age', 'Job', 'Marital', 'Education', 'Default', 'Balance', 'HHInsurance', 'CarLoan', 'Communication', 'LastContactDay', 'LastContactMonth', 'NoOfContacts', 'DaysPassed', 'PrevAttempts', 'Outcome', 'CallStart', 'CallEnd', 'CarInsurance']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('C:/Users/lhaye/Documents/Genesys_Task_Dataset/carInsurance_train.csv')\n",
    "test_df = pd.read_csv('C:/Users/lhaye/Documents/Genesys_Task_Dataset/carInsurance_test.csv')\n",
    "\n",
    "print(train_df['Id'])\n",
    "\n",
    "#LETS PUT THE COLUMNS INTO A LIST SO WE CAN SEE WHICH ONES CORRESPOND TO FEATURES AND WHICH TO \n",
    "columns = train_df.columns.tolist()\n",
    "feature_columns = columns[:-1]\n",
    "output_column = columns[-1:]\n",
    "num_train_samples = train_df.shape[0]\n",
    "\n",
    "print(columns)\n",
    "\n",
    "#Okay so lets do some analysis of the data \n",
    "#print(train_df.shape)\n",
    "\n",
    "#We can see from this that we have many categorical features which we will have to transform into numeric features\n",
    "#print(train_df.info)\n",
    "\n",
    "#Lets also check the types and we can see that the object type represents a categorical feature which we will have to change\n",
    "#print(train_df.dtypes)\n",
    "\n",
    "#Any preprocessing we do should be done in a function because we will have to do the same for the test set \n",
    "#We need to check for and deal with the following if they are present:\n",
    "#1 Missing data (na or nan)\n",
    "#2 Duplicate data - samples that are present twice - we can just remove one if they are identical \n",
    "#3 Modify categorical features\n",
    "#4 Outliers - values that are very high for example we can see that there has been 12 previous attempts to contact one customer\n",
    "#5 Create some new features from the data\n",
    "#6 Remove irrelevant features/columns \n",
    " \n",
    "\n",
    "#Lets get the preprocessed data and then make alterations to it based on the model score \n",
    "def preprocess_data(data):\n",
    "    \n",
    "    #1 Missing data \n",
    "    #print(data.isnull().sum())\n",
    "    #We can see that the columns with missing data is present where we have categorical data so when we change these \n",
    "    #to numeric data we can simply add in a value to represent NA - This should sort this issue \n",
    "    \n",
    "    #2 Duplicate data\n",
    "    duplicate_rows_df = data[data.duplicated()]\n",
    "    #print('number of duplicate rows: ', duplicate_rows_df.shape)\n",
    "    #We can see we have zero duplicated rows of data \n",
    "    \n",
    "    \n",
    "    #3 Modify all data that is Na with a word to avoid difficulties \n",
    "    data['Education'] = data['Education'].fillna(\"NoVal\")\n",
    "    data['Job'] = data['Job'].fillna(\"NoVal\")\n",
    "    data['Communication'] = data['Communication'].fillna(\"NoVal\")\n",
    "    data['Outcome'] = data['Outcome'].fillna(\"NoVal\")\n",
    "\n",
    "    #We tranlsate the categorical labels into numeric labels \n",
    "    ord_enc = OrdinalEncoder()\n",
    "    #print(data)\n",
    "    data[\"Education\"] = ord_enc.fit_transform(data[[\"Education\"]])\n",
    "    data[\"Marital\"] = ord_enc.fit_transform(data[[\"Marital\"]])\n",
    "    data[\"Job\"] = ord_enc.fit_transform(data[[\"Job\"]])\n",
    "    data[\"Outcome\"] = ord_enc.fit_transform(data[[\"Outcome\"]])\n",
    "    data[\"Communication\"] = ord_enc.fit_transform(data[[\"Communication\"]])\n",
    "\n",
    "    #Create a feature for the duration of the call \n",
    "    data['CallStart'] = pd.to_datetime(data[\"CallStart\"])\n",
    "    data['CallEnd'] = pd.to_datetime(data[\"CallEnd\"])\n",
    "\n",
    "    data['CallStart'] = (data['CallStart'].dt.hour*60+data['CallStart'].dt.minute)*60 + data['CallStart'].dt.second\n",
    "    data['CallEnd'] = (data['CallEnd'].dt.hour*60+data['CallEnd'].dt.minute)*60 + data['CallEnd'].dt.second\n",
    "    \n",
    "    data['CallDuration'] = data['CallEnd'] - data['CallStart']\n",
    "    #Now we have the feature and some of the values are quite large so perhaps they should be normalised \n",
    "    \n",
    "    #Now we should drop some features that we dont need \n",
    "    data = data.drop(['Id', 'LastContactDay', 'LastContactMonth', 'CallStart', 'CallEnd'], axis=1)\n",
    "    \n",
    "    #Now we need to normalise/put into smaller values the following columns\n",
    "    # Balance\n",
    "    # DaysPassed\n",
    "    # NoOfContacts\n",
    "    \n",
    "    #NORMALIZATION WE CAN TAKE THIS OUT DEPENDENT ON WHAT ALGORITHM WE USE \n",
    "    # Maybe because the max is so infrequent we should do a different form of normalization but we can see later\n",
    "    data['Balance'] = (data['Balance'] - data['Balance'].min()) / (data['Balance'].max() - data['Balance'].min())\n",
    "    data['NoOfContacts'] = (data['NoOfContacts'] - data['NoOfContacts'].min()) / (data['NoOfContacts'].max() - data['NoOfContacts'].min())\n",
    "    data['Age'] = (data['Age'] - data['Age'].min()) / (data['Age'].max() - data['Age'].min())\n",
    "    data['DaysPassed'] = (data['DaysPassed'] - data['DaysPassed'].min()) / (data['DaysPassed'].max() - data['DaysPassed'].min())\n",
    "    data['PrevAttempts'] = (data['PrevAttempts'] - data['PrevAttempts'].min()) / (data['PrevAttempts'].max() - data['PrevAttempts'].min())\n",
    "    data['CallDuration'] = (data['CallDuration'] - data['CallDuration'].min()) / (data['CallDuration'].max() - data['CallDuration'].min())\n",
    "    data['Job'] = (data['Job'] - data['Job'].min()) / (data['Job'].max() - data['Job'].min())\n",
    "    data['Education'] = (data['Education'] - data['Education'].min()) / (data['Education'].max() - data['Education'].min())\n",
    "    data['Marital'] = (data['Marital'] - data['Marital'].min()) / (data['Marital'].max() - data['Marital'].min())\n",
    "    data['Communication'] = (data['Communication'] - data['Communication'].min()) / (data['Communication'].max() - data['Communication'].min())\n",
    "\n",
    "    print(len(data))\n",
    "    \n",
    "    return data\n",
    "    #Okay so now we have the features we need so we can return them and see how it would go on a dataset\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "1\n",
      "      CarInsurance\n",
      "3215             0\n",
      "3126             0\n",
      "697              0\n",
      "3613             0\n",
      "2374             1\n",
      "...            ...\n",
      "1130             0\n",
      "1294             0\n",
      "860              1\n",
      "3507             1\n",
      "3174             0\n",
      "\n",
      "[2800 rows x 1 columns]\n",
      "           Age       Job  Marital  Education  Default   Balance  HHInsurance  \\\n",
      "0     0.181818  0.454545      1.0   1.000000        0  0.042138            1   \n",
      "1     0.181818  0.181818      0.5   0.333333        0  0.041527            1   \n",
      "2     0.142857  0.454545      1.0   1.000000        0  0.036413            1   \n",
      "3     0.090909  0.818182      1.0   0.333333        0  0.033811            1   \n",
      "4     0.155844  0.454545      0.5   1.000000        0  0.056684            0   \n",
      "...        ...       ...      ...        ...      ...       ...          ...   \n",
      "3995  0.129870  0.909091      1.0   1.000000        0  0.030136            1   \n",
      "3996  0.402597  0.090909      0.0   0.666667        0  0.031357            1   \n",
      "3997  0.116883  0.090909      1.0   0.666667        0  0.026194            0   \n",
      "3998  0.233766  0.272727      1.0   1.000000        0  0.036620            1   \n",
      "3999  0.350649  0.727273      0.5   0.333333        0  0.031486            1   \n",
      "\n",
      "      CarLoan  Communication  NoOfContacts  DaysPassed  PrevAttempts  Outcome  \\\n",
      "0           0            1.0      0.023810    0.000000      0.000000      0.0   \n",
      "1           0            0.0      0.095238    0.000000      0.000000      0.0   \n",
      "2           0            0.5      0.000000    0.140351      0.017241      1.0   \n",
      "3           0            0.5      0.023810    0.000000      0.000000      0.0   \n",
      "4           0            0.5      0.000000    0.000000      0.000000      0.0   \n",
      "...       ...            ...           ...         ...           ...      ...   \n",
      "3995        0            0.5      0.000000    0.047953      0.034483      1.0   \n",
      "3996        1            0.5      0.428571    0.000000      0.000000      0.0   \n",
      "3997        1            0.5      0.000000    0.000000      0.000000      0.0   \n",
      "3998        0            0.5      0.000000    0.266667      0.051724      1.0   \n",
      "3999        0            0.0      0.023810    0.000000      0.000000      0.0   \n",
      "\n",
      "      CallDuration  \n",
      "0         0.020012  \n",
      "1         0.055419  \n",
      "2         0.103140  \n",
      "3         0.250616  \n",
      "4         0.057574  \n",
      "...            ...  \n",
      "3995      0.081281  \n",
      "3996      0.036946  \n",
      "3997      0.087746  \n",
      "3998      0.028941  \n",
      "3999      0.082820  \n",
      "\n",
      "[4000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train_processed = preprocess_data(train_df)\n",
    "print(len(output_column))\n",
    "y_train_vals = train_df[output_column]\n",
    "x_train_processed = x_train_processed.drop(labels='CarInsurance', axis=1)\n",
    "print(y_train)\n",
    "\n",
    "\n",
    "print(x_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Age       Job  Marital  Education  Default   Balance  HHInsurance  \\\n",
      "0     0.181818  0.454545      1.0   1.000000        0  0.042138            1   \n",
      "1     0.181818  0.181818      0.5   0.333333        0  0.041527            1   \n",
      "2     0.142857  0.454545      1.0   1.000000        0  0.036413            1   \n",
      "3     0.090909  0.818182      1.0   0.333333        0  0.033811            1   \n",
      "4     0.155844  0.454545      0.5   1.000000        0  0.056684            0   \n",
      "...        ...       ...      ...        ...      ...       ...          ...   \n",
      "3995  0.129870  0.909091      1.0   1.000000        0  0.030136            1   \n",
      "3996  0.402597  0.090909      0.0   0.666667        0  0.031357            1   \n",
      "3997  0.116883  0.090909      1.0   0.666667        0  0.026194            0   \n",
      "3998  0.233766  0.272727      1.0   1.000000        0  0.036620            1   \n",
      "3999  0.350649  0.727273      0.5   0.333333        0  0.031486            1   \n",
      "\n",
      "      CarLoan  Communication  NoOfContacts  DaysPassed  PrevAttempts  Outcome  \\\n",
      "0           0            1.0      0.023810    0.000000      0.000000      0.0   \n",
      "1           0            0.0      0.095238    0.000000      0.000000      0.0   \n",
      "2           0            0.5      0.000000    0.140351      0.017241      1.0   \n",
      "3           0            0.5      0.023810    0.000000      0.000000      0.0   \n",
      "4           0            0.5      0.000000    0.000000      0.000000      0.0   \n",
      "...       ...            ...           ...         ...           ...      ...   \n",
      "3995        0            0.5      0.000000    0.047953      0.034483      1.0   \n",
      "3996        1            0.5      0.428571    0.000000      0.000000      0.0   \n",
      "3997        1            0.5      0.000000    0.000000      0.000000      0.0   \n",
      "3998        0            0.5      0.000000    0.266667      0.051724      1.0   \n",
      "3999        0            0.0      0.023810    0.000000      0.000000      0.0   \n",
      "\n",
      "      CallDuration  \n",
      "0         0.020012  \n",
      "1         0.055419  \n",
      "2         0.103140  \n",
      "3         0.250616  \n",
      "4         0.057574  \n",
      "...            ...  \n",
      "3995      0.081281  \n",
      "3996      0.036946  \n",
      "3997      0.087746  \n",
      "3998      0.028941  \n",
      "3999      0.082820  \n",
      "\n",
      "[4000 rows x 14 columns]\n",
      "2800\n",
      "           Age       Job  Marital  Education  Default   Balance  HHInsurance  \\\n",
      "3215  0.168831  0.909091      0.0   0.666667        0  0.018458            1   \n",
      "3126  0.207792  0.909091      1.0   1.000000        0  0.032382            1   \n",
      "697   0.376623  0.909091      1.0   0.666667        0  0.036048            0   \n",
      "3613  0.181818  0.090909      1.0   1.000000        0  0.045223            1   \n",
      "2374  0.285714  0.090909      0.0   0.666667        0  0.051116            0   \n",
      "...        ...       ...      ...        ...      ...       ...          ...   \n",
      "1130  0.480519  0.000000      0.5   1.000000        0  0.030136            0   \n",
      "1294  0.337662  0.909091      0.5   0.666667        0  0.165745            1   \n",
      "860   0.298701  0.181818      0.5   0.333333        0  0.032560            0   \n",
      "3507  0.194805  0.909091      0.5   0.666667        0  0.035625            0   \n",
      "3174  0.181818  0.181818      0.5   0.666667        0  0.037182            1   \n",
      "\n",
      "      CarLoan  Communication  NoOfContacts  DaysPassed  PrevAttempts  Outcome  \\\n",
      "3215        0            0.0      0.095238    0.000000      0.000000      0.0   \n",
      "3126        0            0.5      0.071429    0.000000      0.000000      0.0   \n",
      "697         1            0.5      0.023810    0.000000      0.000000      0.0   \n",
      "3613        0            0.5      0.000000    0.412865      0.086207      1.0   \n",
      "2374        0            0.5      0.000000    0.000000      0.000000      0.0   \n",
      "...       ...            ...           ...         ...           ...      ...   \n",
      "1130        0            0.0      0.000000    0.000000      0.000000      0.0   \n",
      "1294        0            0.0      0.000000    0.000000      0.000000      0.0   \n",
      "860         0            0.0      0.047619    0.000000      0.000000      0.0   \n",
      "3507        0            0.5      0.000000    0.000000      0.000000      0.0   \n",
      "3174        0            0.0      0.023810    0.000000      0.000000      0.0   \n",
      "\n",
      "      CallDuration  \n",
      "3215      0.023399  \n",
      "3126      0.117611  \n",
      "697       0.051724  \n",
      "3613      0.016318  \n",
      "2374      0.137623  \n",
      "...            ...  \n",
      "1130      0.010160  \n",
      "1294      0.018473  \n",
      "860       0.208744  \n",
      "3507      0.111453  \n",
      "3174      0.031712  \n",
      "\n",
      "[2800 rows x 14 columns]\n",
      "      CarInsurance\n",
      "3215             0\n",
      "3126             0\n",
      "697              0\n",
      "3613             0\n",
      "2374             1\n",
      "...            ...\n",
      "1130             0\n",
      "1294             0\n",
      "860              1\n",
      "3507             1\n",
      "3174             0\n",
      "\n",
      "[2800 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#create a dataframe with the train and test \n",
    "#train_df = pd.concat([x_train, y_train], axis=1)\n",
    "\n",
    "print(x_train_processed)\n",
    "print(len(y_train))\n",
    "\n",
    "#Now we should create a train and validation split of the data and do some predictions\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train_processed, y_train_vals, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-255-c731a006f7e9>:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  RFModel.fit(X_train, y_train)\n",
      "<ipython-input-255-c731a006f7e9>:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  KNNModel.fit(X_train, y_train)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\lhaye\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', SVC(kernel='linear')),\n",
       "                             ('boost',\n",
       "                              GradientBoostingClassifier(learning_rate=1,\n",
       "                                                         max_depth=1,\n",
       "                                                         random_state=1)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(n_estimators=150,\n",
       "                                                     random_state=1))])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Now we can run an algorithm and see \n",
    "#start with Logistic regression\n",
    "\n",
    "LRmodel = LogisticRegression()\n",
    "LRmodel = LRmodel.fit(X_train, y_train)\n",
    "\n",
    "SVMmodelLinear = svm.SVC(kernel='linear') # Linear Kernel\n",
    "SVMmodelLinear.fit(X_train, y_train)\n",
    "\n",
    "SVMmodelRbf= svm.SVC(kernel='rbf') # Linear Kernel\n",
    "SVMmodelRbf.fit(X_train, y_train)\n",
    "\n",
    "SVMmodelNuSVC = svm.NuSVC(gamma='auto')\n",
    "SVMmodelNuSVC.fit(X_train, y_train)\n",
    "\n",
    "RFModel = RandomForestClassifier(n_estimators = 150, random_state=1)\n",
    "RFModel.fit(X_train, y_train)\n",
    "\n",
    "DTModel = DecisionTreeClassifier(max_depth=1)\n",
    "DTModel.fit(X_train, y_train)\n",
    "\n",
    "KNNModel = KNeighborsClassifier(n_neighbors=5)\n",
    "KNNModel.fit(X_train, y_train)\n",
    "\n",
    "#Implement a boosting algorithm\n",
    "boosting = GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=1, random_state=1)\n",
    "boosting.fit(X_train, y_train)\n",
    "\n",
    "#Ensemble with 'hard' vote i.e. majority rules\n",
    "ensemble = VotingClassifier( estimators=[('lr', SVMmodelLinear), ('boost', boosting), ('rf', RFModel)], voting = 'hard')\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "#Implement a stacking algorithm \n",
    "\n",
    "\n",
    "#Need to have very good understanding of trees, random forest and SVM \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:               0.7933333333333333\n",
      "SVM Linear Accuracy:                        0.8\n",
      "SVM SVC Accuracy:                           0.8016666666666666\n",
      "SVM NuSVC Accuracy:                         0.8075\n",
      "Random Forrest Accuracy:                    0.8333333333333334\n",
      "Decision Tree Accuracy:                     0.7583333333333333\n",
      "K-Nearest Neighbours Accuracy:              0.7433333333333333\n",
      "Ensemble Accuracy:                          0.8233333333333334\n",
      "Boosting Accuracy:                          0.8158333333333333\n",
      "\n",
      "Logistic Regression Precision:             0.7927461139896373\n",
      "SVM Precision Linear:                      0.798469387755102\n",
      "SVM Precision SVC:                         0.797979797979798\n",
      "SVM Precision NuSVC:                       0.8091603053435115\n",
      "Random Forest Precision:                   0.7854166666666667\n",
      "Decision Tree Precision:                   0.7459893048128342\n",
      "K-Nearest Neighbours Precision:            0.7034313725490197\n",
      "Ensemble Precision:                        0.7924107142857143\n",
      "Boosting Precision:                        0.7817371937639198\n"
     ]
    }
   ],
   "source": [
    "#Lets use the logistic regression algorithm and get a result\n",
    "LRpredictions = LRmodel.predict(X_test)\n",
    "LRscore = accuracy_score(y_test, LRpredictions)\n",
    "LRPrecision = metrics.precision_score(y_test, LRpredictions)\n",
    "\n",
    "#Now lets use SVM and do the same \n",
    "SVMpredictionsLinear = SVMmodelLinear.predict(X_test)\n",
    "SVMscoreLinear = accuracy_score(y_test, SVMpredictionsLinear)\n",
    "SVMPrecisionLinear = metrics.precision_score(y_test, SVMpredictionsLinear)\n",
    "\n",
    "SVMpredictionsRbf = SVMmodelRbf.predict(X_test)\n",
    "SVMscoreRbf = accuracy_score(y_test, SVMpredictionsRbf)\n",
    "SVMPrecisionRbf = metrics.precision_score(y_test, SVMpredictionsRbf)\n",
    "\n",
    "SVMpredictionsNuSVC = SVMmodelNuSVC.predict(X_test)\n",
    "SVMscoreNuSVC = accuracy_score(y_test, SVMpredictionsNuSVC)\n",
    "SVMPrecisionNuSVC = metrics.precision_score(y_test, SVMpredictionsNuSVC)\n",
    "\n",
    "RFpredictions = RFModel.predict(X_test)\n",
    "RFscore = accuracy_score(y_test, RFpredictions)\n",
    "RFPrecision = metrics.precision_score(y_test, RFpredictions)\n",
    "\n",
    "DTpredictions = DTModel.predict(X_test)\n",
    "DTscore = accuracy_score(y_test, DTpredictions)\n",
    "DTPrecision = metrics.precision_score(y_test, DTpredictions)\n",
    "\n",
    "KNNpredictions = KNNModel.predict(X_test)\n",
    "KNNscore = accuracy_score(y_test, KNNpredictions)\n",
    "KNNPrecision = metrics.precision_score(y_test, KNNpredictions)\n",
    "\n",
    "Ensemblepredictions = ensemble.predict(X_test)\n",
    "Ensemblescore = accuracy_score(y_test, Ensemblepredictions)\n",
    "EnsemblePrecision = metrics.precision_score(y_test, Ensemblepredictions)\n",
    "\n",
    "Boostingpredictions = boosting.predict(X_test)\n",
    "Boostingscore = accuracy_score(y_test, Boostingpredictions)\n",
    "BoostingPrecision = metrics.precision_score(y_test, Boostingpredictions)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:              \", LRscore)\n",
    "print(\"SVM Linear Accuracy:                       \", SVMscoreLinear)\n",
    "print(\"SVM SVC Accuracy:                          \", SVMscoreRbf)\n",
    "print(\"SVM NuSVC Accuracy:                        \", SVMscoreNuSVC)\n",
    "print(\"Random Forrest Accuracy:                   \", RFscore)\n",
    "print(\"Decision Tree Accuracy:                    \", DTscore)\n",
    "print(\"K-Nearest Neighbours Accuracy:             \", KNNscore)\n",
    "print(\"Ensemble Accuracy:                         \", Ensemblescore)\n",
    "print(\"Boosting Accuracy:                         \", Boostingscore)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Logistic Regression Precision:            \", LRPrecision)\n",
    "print(\"SVM Precision Linear:                     \", SVMPrecisionLinear)\n",
    "print(\"SVM Precision SVC:                        \", SVMPrecisionRbf)\n",
    "print(\"SVM Precision NuSVC:                      \", SVMPrecisionNuSVC)\n",
    "print(\"Random Forest Precision:                  \", RFPrecision)\n",
    "print(\"Decision Tree Precision:                  \", DTPrecision)\n",
    "print(\"K-Nearest Neighbours Precision:           \", KNNPrecision)\n",
    "print(\"Ensemble Precision:                       \", EnsemblePrecision)\n",
    "print(\"Boosting Precision:                       \", BoostingPrecision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
